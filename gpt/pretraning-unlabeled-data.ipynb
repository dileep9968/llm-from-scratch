{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b0deea",
   "metadata": {},
   "source": [
    "### Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5149f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tiktoken\n",
    "#!pip install tensorflow torch\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca420ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.3\n",
      "numpy version: 2.1.3\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.5.1\n",
      "tensorflow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",\n",
    "    'numpy',\n",
    "    'tiktoken',\n",
    "    'torch',\n",
    "    'tensorflow'\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa31361",
   "metadata": {},
   "source": [
    "### 5.1.1 Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d20e6072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from gpt import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\":50257,\n",
    "    \"context_length\":256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\":12,\n",
    "    \"n_layers\":12,\n",
    "    \"drop_rate\":0.1,\n",
    "    \"qkv_bias\":False\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval() # Disable dropout durning inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1df09ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: \n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from gpt import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text,allowed_special = {\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimesnions\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove the batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "\n",
    "print(\"Output text: \\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44894f4",
   "metadata": {},
   "source": [
    "### 5.1.2 Calculating the text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "880a644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32b90723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)  # probability of each token in vocabulary\n",
    "print(probas.shape)  #(batch_size, num_tokens, vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32509e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID: \n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim =-1, keepdim=True)\n",
    "print('Token ID: \\n', token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7391344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Output batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Output batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "609dbc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4514e-05, 3.1054e-05, 1.1567e-05])\n",
      "Text 2: tensor([1.0343e-05, 5.6737e-05, 4.7620e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06ad907d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5045, -10.3798, -11.3674, -11.4792,  -9.7771, -12.2549])\n"
     ]
    }
   ],
   "source": [
    "# Compute logratithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7997756a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7938)\n"
     ]
    }
   ],
   "source": [
    "# calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43b399d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7938)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a0bdfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "830f5701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print('Flattened logits:',logits_flat.shape)\n",
    "print('Flattened targets:', targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be7e149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7938)\n"
     ]
    }
   ],
   "source": [
    "# apply the cross_entropy \n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c84664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48717.6914)\n"
     ]
    }
   ],
   "source": [
    "# perplexity is simply the exponential of the cross-entropy loss\n",
    "# It measure of how well the probability distribution predicated by the model matches the actual \n",
    "# actual distribution of the words in the dataset\n",
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de28acc8",
   "metadata": {},
   "source": [
    "### 5.1.3 Calculating the traning and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "873a2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write((text_data))\n",
    "else:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1800fa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# First 100 character\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6acefdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# Last 100 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f12ea8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b0d2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt import create_dataloader_v1\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7abb35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e3d0f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print('Train loader:')\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print('\\nValidation loader:')\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08064242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning tokens:  4608\n",
      "Validation tokens:  512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "# checking the token size\n",
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Traning tokens: \", train_tokens)\n",
    "print(\"Validation tokens: \", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1225b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) ==0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return total_loss/num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca892dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning loss:  10.987385114034018\n",
      "Validation loss:  10.980905532836914\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print('Traning loss: ', train_loss)\n",
    "print('Validation loss: ', val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac422d4",
   "metadata": {},
   "source": [
    "### 5.2 Traning an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cb58e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_sample(model,train_loader,val_loader,optimizer,device,num_epoches,eval_freq,eval_iter,start_context,tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [],[],[]\n",
    "    tokens_seen, global_step = 0,-1\n",
    "\n",
    "    #Main traning loop\n",
    "    for epoch in range(num_epoches):\n",
    "        model.train()    # set to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() #calculate loss gradients\n",
    "            optimizer.step() #update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq ==0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"EP {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, val loss {val_loss:.3f}\")\n",
    "\n",
    "    # Print a sample text after each epochs\n",
    "    generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device,eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device,num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device,num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model = model,\n",
    "            idx = encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace('\\n',' ')) # compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f5e0276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP 1 (Step 000000): Train loss 9.784, val loss 9.928\n",
      "EP 1 (Step 000005): Train loss 7.986, val loss 8.336\n",
      "EP 2 (Step 000010): Train loss 6.754, val loss 7.049\n",
      "EP 2 (Step 000015): Train loss 6.114, val loss 6.573\n",
      "EP 3 (Step 000020): Train loss 5.525, val loss 6.489\n",
      "EP 3 (Step 000025): Train loss 5.325, val loss 6.389\n",
      "EP 4 (Step 000030): Train loss 4.766, val loss 6.361\n",
      "EP 4 (Step 000035): Train loss 4.462, val loss 6.255\n",
      "EP 5 (Step 000040): Train loss 3.835, val loss 6.196\n",
      "EP 6 (Step 000045): Train loss 3.356, val loss 6.140\n",
      "EP 6 (Step 000050): Train loss 2.865, val loss 6.112\n",
      "EP 7 (Step 000055): Train loss 2.352, val loss 6.139\n",
      "EP 7 (Step 000060): Train loss 2.090, val loss 6.179\n",
      "EP 8 (Step 000065): Train loss 1.526, val loss 6.175\n",
      "EP 8 (Step 000070): Train loss 1.277, val loss 6.177\n",
      "EP 9 (Step 000075): Train loss 1.004, val loss 6.276\n",
      "EP 9 (Step 000080): Train loss 0.722, val loss 6.280\n",
      "EP 10 (Step 000085): Train loss 0.509, val loss 6.322\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n",
      "Training completed in 14.77 minutes.\n"
     ]
    }
   ],
   "source": [
    "# start the llm training\n",
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, token_seen = train_model_sample(\n",
    "    model, train_loader, val_loader, optimizer, device,num_epoches=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context='Every effort moves you', tokenizer=tokenizer\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time-start_time)/60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1e4ccf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, token_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc8c8b",
   "metadata": {},
   "source": [
    "### 5.3 Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0fd88c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids('Every effort moves you', tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "\n",
    "print('Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbf071f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    'closer':0,\n",
    "    'every':1,\n",
    "    'effort':2,\n",
    "    'forward':3,\n",
    "    'inches':4,\n",
    "    'moves':5,\n",
    "    'pizza':6,\n",
    "    'toward':7,\n",
    "    'you':8\n",
    "}\n",
    "\n",
    "inverse_vocab = {v:k for k, v in vocab.items()}\n",
    "\n",
    "# Suppose input is 'every effort moves you' and the LLM\n",
    "# returns the following logits for the next token\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# The next generated token is then as follows\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4946b3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dce84f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c38ec092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits/temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1,0.1, 5] # original, higher confidence and lower confidence\n",
    "\n",
    "# calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6488d669",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Axes' object has no attribute 'set_xtickslabels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbability\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xticks(x)\n\u001b[1;32m---> 11\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_xtickslabels\u001b[49m(vocab\u001b[38;5;241m.\u001b[39mkeys(), rotation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m90\u001b[39m)\n\u001b[0;32m     12\u001b[0m ax\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Axes' object has no attribute 'set_xtickslabels'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ploting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x+i*bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xtickslabels(vocab.keys(), rotation = 90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('temperature-plt.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67658829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "992 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "8 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6982b693",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52664e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits , top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print('Top logits:', top_logits)\n",
    "print('Top positions:', top_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89936e",
   "metadata": {},
   "source": [
    "### 5.3.3 Modifying the text generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae4cab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k = None, eos_id = None):\n",
    "    \n",
    "    # For-loop is the same as before: get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:,-1, :]\n",
    "\n",
    "        # New: filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:,-1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "\n",
    "        # applying temperature scaling\n",
    "        if temperature >0.0:\n",
    "            logits = logits/temperature\n",
    "\n",
    "            # Apply softmax to get probablities\n",
    "            probs = torch.softmax(logits, dim=-1) # (batch_size, context_len)\n",
    "\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples =1) # ( batch_size, 1)\n",
    "        \n",
    "        # Otherwise same as before: get idx of the vocab entry with highest logits values\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True) #(batch_size,1)\n",
    "        \n",
    "        if idx_next == eos_id: # stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "        # same as before append samples index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1) #(batch_size, num_token+1)\n",
    "    \n",
    "    return idx\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9edae94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_idx = generate(\n",
    "    model=model,\n",
    "    idx = text_to_token_ids('Every effort moves you', tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M['context_length'],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print('Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c146c1",
   "metadata": {},
   "source": [
    "### 5.4 Loading and saving model weights in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2dc7aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7137b6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load('model.pth', map_location=device, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d09657c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These adaptive optimizers store additional parameters for each model weights so it makes\n",
    "# sence to save them as well in case we plan to continue the pretraing later\n",
    "torch.save({\n",
    "    'model_state_dict':model.state_dict(),\n",
    "    'optimizer_state_dict':optimizer.state_dict()\n",
    "    },\n",
    "    'model_and_optimizer.pth'\n",
    ")\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "torch.save(optimizer.state_dict(), 'optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f07eb924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14008\\3683350445.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model.pth'))\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14008\\3683350445.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  optimizer.load_state_dict(torch.load('optimizer.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint = torch.load('model_and_optimizer.pth', weights_only=True)\n",
    "\n",
    "# model = GPTModel(GPT_CONFIG_124M)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "# optimizer.load_state_dict(torch.load(checkpoint['optimizer_state_dict']))\n",
    "# model.train()\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(torch.load('optimizer.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a991a9b",
   "metadata": {},
   "source": [
    "### 5.5 Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d0306dbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_name):\n\u001b[1;32m----> 6\u001b[0m     \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloaded to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m BASE_CONFIG \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50257\u001b[39m,     \u001b[38;5;66;03m# Vocabulary size\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1024\u001b[39m,  \u001b[38;5;66;03m# Context length\u001b[39;00m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.0\u001b[39m,        \u001b[38;5;66;03m# Dropout rate\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqkv_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m         \u001b[38;5;66;03m# Query-key-value bias\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     }\n",
      "File \u001b[1;32md:\\RAG-with-open-source-llm\\venv\\lib\\urllib\\request.py:241\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    242\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[1;32md:\\RAG-with-open-source-llm\\venv\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\RAG-with-open-source-llm\\venv\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\RAG-with-open-source-llm\\venv\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\RAG-with-open-source-llm\\venv\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\RAG-with-open-source-llm\\venv\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\RAG-with-open-source-llm\\venv\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "file_name = 'gpt2-smaall-124M.pth'\n",
    "\n",
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded to {file_name}\")\n",
    "BASE_CONFIG = {\n",
    "        \"vocab_size\": 50257,     # Vocabulary size\n",
    "        \"context_length\": 1024,  # Context length\n",
    "        \"drop_rate\": 0.0,        # Dropout rate\n",
    "        \"qkv_bias\": True         # Query-key-value bias\n",
    "    }\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "gpt = GPTModel(BASE_CONFIG)\n",
    "gpt.load_state_dict(torch.load(file_name, weights_only = True))\n",
    "gpt.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gpt.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "tokens_ids = generate(\n",
    "    model = gpt,\n",
    "    idx = text_to_token_ids('Every effort moves you', tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG['context_lenght'],\n",
    "    top_k = 50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print('Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5de79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'version' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTensorflow verison: \u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mversion\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mtensorflow\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mtqdm version:\u001b[39m\u001b[33m'\u001b[39m, version(\u001b[33m'\u001b[39m\u001b[33mtqdm\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'version' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow verison: \", version('tensorflow'))\n",
    "print('tqdm version:', version('tqdm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2021423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_generate import download_and_load_gpt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c901c7df",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: The specified blob does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m settings, params \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_and_load_gpt2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m124M\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSettings:\u001b[39m\u001b[38;5;124m\"\u001b[39m, settings)\n",
      "File \u001b[1;32mc:\\Users\\hp\\OneDrive\\Desktop\\llm-from-scratch\\ch05\\gpt_generate.py:41\u001b[0m, in \u001b[0;36mdownload_and_load_gpt2\u001b[1;34m(model_size, model_dir)\u001b[0m\n\u001b[0;32m     39\u001b[0m     file_url \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_url, model_size, base_url)\n\u001b[0;32m     40\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, filename)\n\u001b[1;32m---> 41\u001b[0m     \u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# load settings and params \u001b[39;00m\n\u001b[0;32m     44\u001b[0m tf_ckpt_path \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mlatest_checkpoint(model_dir)\n",
      "File \u001b[1;32mc:\\Users\\hp\\OneDrive\\Desktop\\llm-from-scratch\\ch05\\gpt_generate.py:52\u001b[0m, in \u001b[0;36mdownload_file\u001b[1;34m(url, destination)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_file\u001b[39m(url, destination):\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# send a get request to download file\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;66;03m# Get the total file size from headers defaulting to 0 if not present\u001b[39;00m\n\u001b[0;32m     54\u001b[0m         file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Length\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;66;03m# check if the files exists and has the same size\u001b[39;00m\n",
      "File \u001b[1;32md:\\RAG-with-open-source-llm\\venv\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\RAG-with-open-source-llm\\venv\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\RAG-with-open-source-llm\\venv\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\RAG-with-open-source-llm\\venv\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\RAG-with-open-source-llm\\venv\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\RAG-with-open-source-llm\\venv\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: The specified blob does not exist."
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", model_dir=\"gpt2\")\n",
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c319ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mParameter dictionary keys:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mparams\u001b[49m.keys())\n",
      "\u001b[31mNameError\u001b[39m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Parameter dictionary keys:\", params.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f6fb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mparams\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mwte\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mToken embedding weight tensor dimensions:\u001b[39m\u001b[33m\"\u001b[39m, params[\u001b[33m\"\u001b[39m\u001b[33mwte\u001b[39m\u001b[33m\"\u001b[39m].shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fdf6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f80f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb57e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac40cfc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m.manual_seed(\u001b[32m123\u001b[39m)\n\u001b[32m      3\u001b[39m token_ids = generate(\n\u001b[32m      4\u001b[39m     model=gpt,\n\u001b[32m      5\u001b[39m     idx=text_to_token_ids(\u001b[33m\"\u001b[39m\u001b[33mEvery effort moves you\u001b[39m\u001b[33m\"\u001b[39m, tokenizer).to(device),\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     temperature=\u001b[32m1.5\u001b[39m\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOutput text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, token_ids_to_text(token_ids, tokenizer))\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d5c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c33fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf824622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
